{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bakzGZqBcVi2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7K7oCTbMcVi4"
      },
      "source": [
        "From here, we have pred, labels, and confidences from the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# START HERE WITH PREPROCESSED FILES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                      feature  label\n",
            "0  [1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1]      0\n",
            "1  [1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0]      1\n",
            "2  [1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1]      1\n",
            "3  [1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1]      1\n",
            "4  [1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1]      1\n",
            "<class 'list'>\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "reconstruct = pd.read_csv(\"rec.csv\")\n",
        "\n",
        "# Convert the feature column from string to list of integers\n",
        "reconstruct[\"feature\"] = reconstruct[\"feature\"].apply(ast.literal_eval)\n",
        "\n",
        "print(reconstruct.head())  # Check the first few rows\n",
        "print(type(df[\"feature\"][0])) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuZssPs_cVi4"
      },
      "source": [
        "#### Manual Error Rate Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqvJBeyHcVi4",
        "outputId": "1b90e37f-ffd8-4f3a-d685-f98a81c46b4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1]\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "print(reconstruct['feature'][0])\n",
        "print(reconstruct['label'][0]) #this is B (U == U*)\n",
        "\n",
        "manual_error = []\n",
        "arr_len = len(reconstruct['feature'][0])\n",
        "tot_enumerations = 2**len(reconstruct['feature'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "1cy1G337esJr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from itertools import product\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def manual_error_rate(df, model, proba=False, diag=False):\n",
        "    features = df['feature']\n",
        "    labels = df['label']\n",
        "\n",
        "    arr_len = len(features[0])\n",
        "    tot_enumerations = 2**arr_len\n",
        "\n",
        "    permutations = list(product([0, 1], repeat=arr_len))\n",
        "\n",
        "    results = []\n",
        "    results_p = []\n",
        "\n",
        "    for perm in tqdm(permutations, total=tot_enumerations, desc=\"Processing permutations\"):\n",
        "        perm_array = np.array(perm)\n",
        "        count = 0\n",
        "        error_count = 0\n",
        "\n",
        "        for feature, label in zip(features, labels):\n",
        "            if np.array_equal(feature, perm_array):\n",
        "                count += 1\n",
        "                if label == 0:\n",
        "                    error_count += 1\n",
        "\n",
        "        if count > 0:\n",
        "          error_rate = (error_count / count)\n",
        "          results.append([perm, error_rate])\n",
        "          proba_score = 0\n",
        "          if proba:\n",
        "            proba_score = model.predict_proba(np.array(perm).reshape(1, -1))[0][0]\n",
        "            results_p.append([perm, proba_score])\n",
        "          if diag: print(f\"permutation {perm}: manual error rate is {error_rate*100:.2f}%, proba_score is {proba_score*100:.2f}% appears {count} times\")\n",
        "\n",
        "    results_array = np.array(results, dtype=object)\n",
        "    results_array_p = np.array(results_p, dtype=object)\n",
        "\n",
        "    if proba: return results_array, results_array_p\n",
        "    else: return results_array\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDRTzgSriD7E"
      },
      "source": [
        "### Manual Error Rate of 100k Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "27Ag5yv2iDwI",
        "outputId": "f2d33cb5-4f3b-452d-c750-233e220d809a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing permutations: 100%|██████████| 16384/16384 [22:11<00:00, 12.31it/s]\n"
          ]
        }
      ],
      "source": [
        "manual_tot = manual_error_rate(reconstruct, rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#save manual_tot, it is a numpy array\n",
        "np.save('manual_tot.npy', manual_tot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5S8pwnRciNNn"
      },
      "source": [
        "### Manual and Proba Error Rate of 10k Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(list(reconstruct['feature']), reconstruct['label'])\n",
        "\n",
        "rf.predict_proba(np.array(reconstruct['feature'][0]).reshape(1, -1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Djza7oojxEL",
        "outputId": "0df3aa26-2f94-4818-e135-c519cfb0aebc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing permutations: 100%|██████████| 16384/16384 [04:53<00:00, 55.74it/s]\n"
          ]
        }
      ],
      "source": [
        "sample_rec = reconstruct.sample(n=10000, random_state=42)\n",
        "#reset index\n",
        "sample_rec = sample_rec.reset_index(drop=True)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(list(sample_rec['feature']), sample_rec['label'])\n",
        "\n",
        "manual_sample, proba_sample = manual_error_rate(sample_rec, rf, proba=True, diag=False)\n",
        "\n",
        "np.save('manual_sample.npy', manual_sample)\n",
        "np.save('proba_sample.npy', proba_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWrRr1tNikBj"
      },
      "source": [
        "#### R^2 Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "proba_sample = np.load('proba_sample.npy', allow_pickle=True)\n",
        "manual_sample = np.load('manual_sample.npy', allow_pickle=True)\n",
        "manual_tot = np.load('manual_tot.npy', allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 0.003081969274486076],\n",
              "       [(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1), 0.9881310502789765],\n",
              "       [(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0), 0.0],\n",
              "       ...,\n",
              "       [(1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1), 0.0941904761904762],\n",
              "       [(1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0), 0.05371428571428571],\n",
              "       [(1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0), 0.5415576645576643]],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "proba_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0) 0.003424657534246575]\n",
            " [(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1) 0.9859154929577465]\n",
            " [(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0) 0.0]\n",
            " ...\n",
            " [(1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1) 0.0]\n",
            " [(1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0) 0.0]\n",
            " [(1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0) 0.5]]\n"
          ]
        }
      ],
      "source": [
        "# only keep permutations that are present in sample_rec\n",
        "import numpy as np\n",
        "\n",
        "# Convert lists of features in proba_sample and manual_sample into sets for quick lookup\n",
        "proba_features = {tuple(entry[0]) for entry in proba_sample}\n",
        "manual_sample_features = {tuple(entry[0]) for entry in manual_sample}\n",
        "\n",
        "# Find the intersection of features in both proba_sample and manual_sample\n",
        "common_features = proba_features & manual_sample_features\n",
        "\n",
        "# Filter manual_tot to keep only entries with features in common_features\n",
        "manual_tot_sheared = np.array([entry for entry in manual_tot if tuple(entry[0]) in common_features], dtype=object)\n",
        "\n",
        "print(manual_tot_sheared)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0) 0.003424657534246575]\n",
            " [(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1) 0.9859154929577465]\n",
            " [(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0) 0.0]\n",
            " ...\n",
            " [(1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1) 0.0]\n",
            " [(1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0) 0.0]\n",
            " [(1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0) 0.5]]\n"
          ]
        }
      ],
      "source": [
        "print(manual_tot_sheared)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0) 0.017241379310344827]\n",
            " [(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1) 1.0]\n",
            " [(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0) 0.0]\n",
            " ...\n",
            " [(1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1) 0.0]\n",
            " [(1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0) 0.0]\n",
            " [(1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0) 1.0]]\n"
          ]
        }
      ],
      "source": [
        "print(manual_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0) 0.003081969274486076]\n",
            " [(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1) 0.9881310502789765]\n",
            " [(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0) 0.0]\n",
            " ...\n",
            " [(1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1) 0.0941904761904762]\n",
            " [(1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0) 0.05371428571428571]\n",
            " [(1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0) 0.5415576645576643]]\n"
          ]
        }
      ],
      "source": [
        "print(proba_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.003424657534246575, 0.9859154929577465, 0.0, ..., 0.0, 0.0, 0.5],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "manual_tot_sheared[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "WSTr_C9piDty"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9585035263308146\n",
            "0.2822243456534057\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "#r2 for proba_sample and manual_tot\n",
        "print(r2_score(manual_tot_sheared[:, 1], proba_sample[:, 1]))\n",
        "\n",
        "#r2 for manual_sample and manual_tot\n",
        "print(r2_score(manual_tot_sheared[:, 1], manual_sample[:, 1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
